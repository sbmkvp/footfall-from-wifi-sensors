The main study was designed to validate the results of the pilot study over different locations at different times. 
We choose five different locations across central London, to install the sensors and collect data for a long period of time. 
We also carry out manual counting on these locations along with this across different time of the day. 
We then apply the filtering based on signal strength and sequence numbers and compare with manual counts and evaluate the effectiveness of the process with the mean error per minute on these locations. 
Finally we calculate the ajustment factor for the first interval of manual counts and check if that works on the consecutive intervals. 

The locations where the data were collected are shown in the table. The location are chosen for their variety of configuration and sources of noise. Location 1 is the `cleanest' of while location 2 is the one with the most complexity. The configuration, installation and data collection schedule is shown in the figure. 

\begin{table}
	\tbl{Locations where sensors were installed}
	{\begin{tabular}{clll} 
		\toprule
		 ID & Location & Type & Installation notes\\
		 \midrule
		 1 & Camden High Street & Phone Shop & Bus stop in front\\
		 2 & Central St.Giles Piazza & Restaurant & Seating area on both sides\\
		 3 & Holborn Underground Station & Information Kiosk & Overlooks station entrance\\
		 4 & Brunswick Center & Fast Food Restaurant & Has seating area on one side\\
		 5 & The Strand & Tea Shop & Has phone shop next door \\
		 \bottomrule
	\end{tabular}}
	\label{locations-table}
\end{table}

\begin{figure}
	\begin{center}
		\includegraphics [width=0.90\linewidth] {images/main_schedule.jpeg}
		\caption{Days when the sensors were active at the corresponding location. The red square shows that manual data collection was also done.}
		\label{pilot_clustering}
	\end{center}
\end{figure}

Though data was collected for many continous days, for the purposes of comparing with ground truth we just consider the only the data from sensors corresponding to those sessions. We have 12 sets of data over 6 different days. We have atleast two set manual counts for each location for verification of calibration.

\begin{figure}
	\centering
	\subfigure[Installation configuration of sensors at various locations]{
		\resizebox*{0.46\linewidth}{!}{\includegraphics[trim=20 6 20 6,clip]{images/main_configs.jpeg}}}\hspace{20pt}
	\subfigure[Density distribution of signal strength (lower values show higher signal strength)]{
		\resizebox*{0.46\linewidth}{!}{\includegraphics[trim=20 4 25 6,clip]{images/main_signals.jpeg}}}
	\caption{Distribution of signal strengths across locations} \label{methodology_schematic}
\end{figure}

\subsection{signal strength filtering}
First we see how the distribution of the signal strength varies with location and configuration. 
The density plot for signal strength is shown alogn with configuration in figure.
We can see that the signal strength distribution shows distinct patterns of high and low when the installation is that there is a clear distant source of noise but this distinction get more and more obscure as we move towards difficult installations. 
For example, location 2 is almost a normally distributed noise as it is too far to pick up any pedestrians but location 5 with a clear view of footpath and a phone shop next door shows clear distinction between the two. 
Intuitively the classfication algorithm should give us better results in the latter. 
It is important to note that we are dealing with relative singal strengths, this can vary with location and time of the analysis but we should be still be able to differentiate signal from noise. 
We run the kmeans classification algorithm and filter out the probe requests which are randomised and have signal strengths less than the second break (or the threshold). 
We then count the number of Unique MAC addresses present in every minute and remove MAC addreses which reappear within 30 minutes of previous appearance. 
We then compare this with the minute by minute aggreagation for the manual counts and find the average error per minute for the sensor count. 
The results are shown in the table.We see that the location 2 has the most error 400\% confirming our intuition while surprisingly location 3 has the least error -3\%. 
We also see that the error follows the complexity of the installation. 
It is also very promising that this method alone reduces our margin of error by a 50 - 100\%
For some practical purposes which do not require absolute numbers, this should be sufficient. 
e.g. Indexes of activity and change dashboards and short term trends identification.

We see that the success of the signal strength filtering depends on the how we tackle the problems in the installing the devices.
The more the device in installed in a way that the field of measurement is distinct from its surroundings (however noisy they might be) the more successful this process is.
Closer sources error causes overcounting as we see in 2, 4 but at the same time highly close field of measurement with no big source of error can cause undercounting such as in 3. The complexity of the installation and uniformity of surroundings near the sensors directly coorrelate to the MAPE.
The most effective way of measuring pedestrian is to have the sensor next to have the sensor next to clear area of pedestrian activity and in case of absence of any major source of noise, we should not do the signal strength filtering at all. We can even note the major possible sources of noise around the device and use it to fiugre out the right way of partitioning the data e.g. location 2 and 3 should have different pattern of signal strength filtering depending on their configuration.

\subsection{Clustering based on sequence numbers}

\begin{table}
	\tbl{Data collected at different locations and the correspondin mean absolute percentage error after each filtering process}
	{\begin{tabular}{cccc} 
		\toprule
			Sensor	& MAPE - No Cleaning & MAPE - Signal Strength	& MAPE - Clustering	\\
					& 					 & (efficiency)				& (efficiency)		\\
		 \midrule
			1 & 211 &  56 ( 73)&	\\
			2 & 934 & 400 ( 57)& 	\\
			3 &  88 &  -3 (103)& 	\\
			4 & 501 & 237 ( 53)& 	\\
			5 & 476 & 117 ( 75)& 	\\
		 \bottomrule
	\end{tabular}}
	\label{errors-table}
\end{table}
